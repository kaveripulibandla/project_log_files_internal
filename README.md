# project_log_files_internal

task1: 

creating an increased file from the sample text

task2:

kafka setup - connecting kafka through s3 sink (kafka connector to stream the data using managed kafka)

https://docs.aws.amazon.com/msk/latest/developerguide/mkc-tutorial-setup.html

task3:

Create Virtual Environment On Windows:

https://www.geeksforgeeks.org/creating-python-virtual-environment-windows-linux/


Project_log_files: Steps

STEP 1: Raw_layer

STEP 2: Cleanse_layer

STEP 3 : Cuarated_layer

Loading all the layers data in to locally

All the layers need to have data stored in HIVE and the final curated layer tables need to have data in HIVE and snowflake table

